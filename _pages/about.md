---
permalink: /
title: "Khai-Nguyen Nguyen"
excerpt: "Khai-Nguyen Nguyen"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<style>
body {
    font-family: "Helvetica Neue", Arial, sans-serif;
    font-size: 14px;
    line-height: 1.6;
    color: #333;
}

code {
    font-family: "Source Code Pro", monospace;
    font-size: 12px;
    background-color: #f9f9f9;
    padding: 2px 4px;
    border-radius: 4px;
    color: #c7254e;
    background-color: #f9f2f4;
}

a {
    color: #3498db;
    text-decoration: none;
}

a:hover {
    text-decoration: underline;
}
</style>

I am a CS and Engineering student at Bucknell University at Lewisburg, Pennsylvania. I am particularly interested in methods of improving existing models' learning to reach human-level language understanding.

My work
===


# Human-Level Language Understanding in Models

What does it mean for a model to achieve human-level language understanding, and how do we get there? While the first part of the question is more philosophical, I believe one direction toward the answer to the second part lies in **adopting elements from human language learning** into models.

Toward this end, my research projects in NLP have explored [using visually grounded information to learn better representation in multilingual context](https://arxiv.org/abs/2210.05487) — a technique motivated by the multimodal learning in humans — and [summarizing past texts and incorporating them into the current input](https://github.com/toontran/limitless-sequence-modeling) to capture long-range dependencies — a phenomenon utilized by writers and storytellers in their works.

Towards the answer to the first question, I believe interpretability is of great importance. Many models are said to perform certain tasks at the same level as humans, if not better. However, what attributes to their success? What is the rationale behind their outputs? If we can answer these questions, we are one step closer to understanding the capabilities of the state-of-the-arts, and subsequently could work toward improving them.

My related experience on this topic mainly deals with feedforward networks, but I am exploring ways to extend the methods developed with Professor Serra to the transformer architecture.


CS education
===
I am also interested in work on activities related to education in CS. I have been a teaching assistant for CS2: Data Structures and Algorithms for Bucknell's CS Department for two semesters, which I really enjoyed. I also did research on the identifying which topics are important in CS2 and which are difficult. I hope to be a TA in my graduate studies.



Papers
====

Publications
=====
**Getting away with more network pruning: From sparsity to geometry and linear regions** <br> 
Jeffrey Cai, **Khai-Nguyen Nguyen^{*}**, Nishant Shrestha, Aidan Good, Ruisen Tu, Xin Yu, Shandian Zhe, Thiago Serra <br>
_Workshop on Sparsity in Neural Networks, ICLR 2023_ <br>

**Real-time Speech Summarization for Medical Conversations** <br>
K Le-Duc, **Khai-Nguyen Nguyen^{*}**, L Vo-Dang, TS Hy
arXiv preprint arXiv:2406.15888		2024

**Like a bilingual baby: The advantage of visually grounding a bilingual language model** <br>
**Khai-Nguyen Nguyen**, Zixin Tang, Ankur Mali, M Alex Kelly<br>
_Arxiv, 2022_

**Important and Difficult Topics in CS2: An Expert Consensus via Delphi Study** <br>
Lea Wittie, Anastasia Kurdia, Meriel Huggard, **Khai-Nguyen Nguyen** <br>
_ASEE Annual Conference and Exposition 2023_

Submitted Papers
=====
**Sentiment Reasoning for Healthcare** <br>
Khai Le-Duc, Khai-Nguyen Nguyen^{*}, Bach Phan Tat, Duy Le, Jerry Ngo, Long Vo-Dang, Anh Totti Nguyen, Truong-Son Hy
_Submitted to EMNLP 2024_

**Medical Spoken Named Entity Recognition** <br>
Khai Le-Duc, David Thulke, Hung-Phong Tran, Long Vo-Dang, **Khai-Nguyen Nguyen**, Truong-Son Hy, Ralf Schluter
arXiv preprint arXiv:2406.13337

**Note:** * denotes equal contribution
